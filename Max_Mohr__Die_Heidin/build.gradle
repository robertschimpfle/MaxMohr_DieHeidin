import java.text.SimpleDateFormat

// Wird gebraucht für inputs / outputs Featur der Tasks.
apply plugin: 'base'
apply plugin: 'groovy'
apply plugin: 'eclipse'

defaultTasks 'pdf'

repositories {
	mavenCentral()
}

configurations { cpd }

dependencies {
	compile 'org.codehaus.groovy:groovy-all:2.1.1'
	testCompile 'junit:junit:4.11'
	cpd 'net.sourceforge.pmd:pmd:5.0.3'
}

ext.srcDir = file 'src/main/latex'
ext.resourcesDir = file 'src/main/resources'
ext.buildSrcDir = file 'build/src/main/latex'
ext.inputFile = 'text.tex'
ext.pdfDir = file 'build/pdf'
ext.txtDir = file 'build/txt'
ext.statsDir = file 'build/reports'

task replaceVersionInfo(type: Copy) {
	description = 'Replace the version information in the book.'
	from srcDir
	into buildSrcDir
	include '**/*.tex'
	filter { line ->
		line.replace("@version@", bookVersion)
	}
	filter { line ->
		line.replace("@timestamp@", new SimpleDateFormat("dd.MM.yyyy HH:mm:ss").format(new Date()))
	}
}

task resources(dependsOn: replaceVersionInfo) {
	outputs.file pdfDir
	outputs.file txtDir
	outputs.files statsDir
	doLast {
		pdfDir.mkdirs()
		txtDir.mkdirs()
		statsDir.mkdirs()
	}
}

task latex(dependsOn: ['resources', 'replaceVersionInfo']) {
	inputs.files replaceVersionInfo.outputs
	outputs.file pdfDir
	doLast {
		latexFirstRun.execute()
		latexSecondRun.execute()
		latexThirdRun.execute()
	}
}

task latexFirstRun(type: Exec) {
	commandLine 'pdflatex', '-output-directory', pdfDir, inputFile
	workingDir buildSrcDir
	ignoreExitValue true
	standardOutput = new ByteArrayOutputStream()
	doLast {
		logger.info 'LaTeX first run.'
		if (execResult.getExitValue() != 0) {
			println standardOutput.toString()
			throw execResult.rethrowFailure()
		}
	}
}

task latexSecondRun(type: Exec, dependsOn: latexFirstRun) {
	commandLine 'pdflatex', '-output-directory', pdfDir, inputFile
	workingDir buildSrcDir
	ignoreExitValue true
	standardOutput = new ByteArrayOutputStream()
	doLast {
		logger.info 'LaTeX second run.'
		if (execResult.getExitValue() != 0) {
			println standardOutput.toString()
			throw execResult.rethrowFailure()
		}
	}
}

task latexThirdRun(type: Exec, dependsOn: latexSecondRun) {
	commandLine 'pdflatex', '-output-directory', pdfDir, inputFile
	workingDir buildSrcDir
	doLast {
		logger.info 'LaTeX third run.'
	}
}



// Buchstaben.
def b = 'a-zA-ZÄÖÜäöüßçéèáà'
def sz = '\\.,;:!?«» '

task stripLatexMarkup(dependsOn: ['resources', 'replaceVersionInfo']) {
	description = 'Convert all input LaTeX files to plain text files.'
	inputs.files replaceVersionInfo.outputs
	outputs.file txtDir
	fileTree(dir: buildSrcDir, include: '**/*.tex').each { file ->
		if (! file.text.contains('%%SuppressWarnings("ContentCheck")')) {
			doLast {
				String fileContent = file.text
				logger.info("Working on file ${file.name}")
				
				// Wenn Speicherprobleme, das ganze durch Matcher aus JavaSE ersetzen:
				// An engine that performs match operations on a character sequence by interpreting a Pattern.
				
				def ersetzt = fileContent
				
				// Satzzeichen wieder herstellen.
				ersetzt =
					ersetzt
						.replaceAll(/\\aa(nah){0,1}\{\}/, '«')
						.replaceAll(/\\ae\{\}/, '»')
						.replaceAll(/\\dopp\{\}/, ':')
						.replaceAll(/\\semi\{\}/, ';')
						.replaceAll(/\\frag\{\}/, '?')
						.replaceAll(/\\ausr\{\}/, '!')
						.replaceAll(/\\punkte\{\}/, '...')

				// Ersetze Trenner.
				ersetzt =
					ersetzt.replaceAll(/([${b}])("-|\\-)([${b}])/, '$1$3')

				// Ersetze Ligaturtrenner.
				// TODO not working
				ersetzt =
					ersetzt.replaceAll(/"\|/, '')

				// Getrennte Wörter zusammenziehen.
				ersetzt =
					ersetzt.replaceAll(/(("-|\\-)%\n)(% [${b}]+\n)*([${b}-]+[${sz}]*)/, '$4\n$3')
					
				// Verbundene Wörter zusammenziehen.
				ersetzt =
					ersetzt.replaceAll(/(([${b}]+-)%\n)(% [${b}]+\n)*([${b}-]+[${sz}]*)/, '$2$4\n$3')
					
				// Bindende Zeilenumbrüche entfernen.
				ersetzt =
					ersetzt.replaceAll(/\\\\\*/, '\\\\\\\\')
					
				// begin und end Makros entfernen.
				ersetzt =
					ersetzt.replaceAll(/\\(begin|end)\{.+\}/, '')
					
				// Eingriff- und Label-Makro samt Inhalt entfernen
				ersetzt =
					ersetzt.replaceAll(/\\(eingriff|label)\{.*\}/, '')
					
				exec {
					commandLine('bash', '-c', 'detex - > ' + new File(txtDir, file.name + '.txt'))
					standardInput = new ByteArrayInputStream(ersetzt.getBytes('UTF-8'))
				}
					
//				new File(txtDir, file.name + '.txt').write(ohneEingriff)
			}
		}
	}
}

// Prüfe Vorgaben zur Texteingabe.
task checkTexFiles(dependsOn: replaceVersionInfo) {
	description = 'Check the conformity of the input LaTeX files.'
	def inputFiles  = files { fileTree(dir: srcDir, includes: ['*.tex']) }
	inputs.files inputFiles
	doLast {
		println ""
		inputFiles.each { datei ->
			String fileContent = datei.text
			logger.info("Length of file ${datei.name} = ${fileContent.length()}")
			def lineCounter = 0
			try {
				fileContent.eachLine {
					lineCounter++
				
					// Aussteigen wenn Datei nicht geprüft werden soll.
					if (it =~ /^[ \t]*%%SuppressWarnings\("InputStyle"\)/) {
						throw new Exception("return from closure")
					}
					// Makros die nicht mit { enden.
					if (it =~ /\\[a-zA-Z]+[ \\\t\n\.,;:-]{1,1}/) {
						logger.error("Error: ${datei.name}:${lineCounter}, Makroname nicht mit { oder [ terminiert: \"${it}\"")
					}
					// Mehrfache Leerzeichen.
					if (it =~ / {2}/) {
						logger.error("Error: ${datei.name}:${lineCounter}, mehrfache Leerzeichen: \"${it}\"")
					}
					// Leerzeichen am Zeilenanfang.
					if (it =~ /^ /) {
						logger.error("Error: ${datei.name}:${lineCounter}, Leerzeichen am Zeilenanfang: \"${it}\"")
					}
					// Leerzeichen am Zeilenende.
					if (it =~ /.+ $/) {
						logger.error("Error: ${datei.name}:${lineCounter}, Leerzeichen am Zeilenende: \"${it}\"")
					}
					// Tabulatorzeichen im Text.
					if (it =~ /\t/) {
						logger.error("Error: ${datei.name}:${lineCounter}, Tabulatorzeichen im Text: \"${it}\"")
					}
					// Satzzeichen im Text.
					if (it =~ /[!?:;]/) {
						logger.error("Error: ${datei.name}:${lineCounter}, Plain Satzzeichen (!?:;) im Text: \"${it}\"")
					}
					// Falscher Trenner.
					if (it =~ /[^${b}]\\-[^${b}]/) {
						logger.error("Error: ${datei.name}:${lineCounter}, Falscher Trennstrich: \"${it}\"")
					}
					// Falscher Trenner am Zeilenende wenn mit % abgeschlossen ist.
					if ((it =~ /\\-[^${b}]%.*$/) || (it =~ /\\-%.+$/)) {
						logger.error("Error: ${datei.name}:${lineCounter}, Falscher Trennstrich am Zeilenende: \"${it}\"")
					}
					// Falscher Trenner am Zeilenende wenn nicht mit % abgeschlossen ist. Kommentarzeilen ignorieren.
					if (it =~ /^([^%]|\\%)*[^-%]+[\\]{0,1}-[ \t]*$/) {
						logger.error("Error: ${datei.name}:${lineCounter}, falscher Trennstrich am Zeilenende: \"${it}\"")
					}
				}
			}
			catch (Exception e) {}
		}
	}
}

// Wörter finden, die die Ligatur enthalten und
// in der vorherigen Zeile begonnen haben können
// bzw. in der nächsten Zeile enden können.
// Zusammengesetzte Wörter mit "-" ebenfalls
// berücksichtigen.
task listLigations(dependsOn: ['replaceVersionInfo', 'resources']) {
	description = 'Find tokens that contain ligations, e. g. ff, fl, ...'
	def ausgabe = new File(statsDir, 'ligations.txt')
	def inputFiles  = files { fileTree(dir: srcDir, includes: ['*.tex']) }
	inputs.files inputFiles
	outputs.file ausgabe

	doLast {
		def ligaturen = [['f', 'f'], ['t', 't'], ['f', 'l']]
				
		def liste = []
		inputFiles.each {

			String fileContent = it.text

			if (! fileContent.contains('%%SuppressWarnings("ContentCheck")')) {

				ligaturen.each {
					def ligatur = "${it[0]}(\\-){0,1}${it[1]}"
					def restZeile = "([${b}]|(\\-[${b}]))"
					def restZeile0 = "${restZeile}*"
					def restZeile1 = "${restZeile}+"
					def trennerZeilenende = "\\-%\n"
					def vorherigeZeile =
						"(${restZeile1}${trennerZeilenende}){0,1}"
					def nächsteZeile =
						"(${trennerZeilenende}${restZeile1}){0,1}"

					def matcher =
						fileContent =~
							/${vorherigeZeile}${restZeile0}${ligatur}${restZeile0}${nächsteZeile}/

					matcher.each {
						String wort = it[0].replaceAll('\\\\-', '').replaceAll('%', '').replaceAll('\n', '')
						if (! liste.contains(wort)) { liste.add(wort) }
					}
				}
			}
		}
		ausgabe.write "Im Text gefundene Ligaturwörter mit den Doppelbuchstaben von ${ligaturen}:\n"
		liste.sort{ x, y -> x.compareToIgnoreCase y }.each{ zeile -> ausgabe.withWriterAppend { it.write "${zeile}\n" } }
		ausgabe.withWriterAppend { it.write "\n${liste.size} Wörter\n" }
	}
}


task cpdCheck(type: JavaExec, dependsOn: stripLatexMarkup) {
	description = 'Check for double text passages in the input files.'
	def ausgabe = new File(statsDir, 'cpd.xml')
	inputs.file txtDir
	outputs.file ausgabe
	main 'net.sourceforge.pmd.cpd.CPD'
	classpath fileTree(dir: file('lib'), include: 'pmd*.jar')
	classpath project.configurations.cpd
	args = [
		'--minimum-tokens', minimumDuplicateTokens,
		'--format', 'xml',
		'--encoding', 'UTF-8',
		'--language', 'latex',
		'--files', txtDir
	]
	standardOutput = new ByteArrayOutputStream()
	ignoreExitValue true
	doLast {
		ausgabe.write standardOutput.toString()
	}
}

task copyCss(type: Copy, dependsOn: 'resources') {
	description = 'Copy the CSS for the XML token file.'
	from resourcesDir
	into statsDir
	include 'tokens.css'
}

task tokenFind(dependsOn: ['stripLatexMarkup', 'copyCss']) {
	description = 'List all tokens found in the input files.'
	def inputFiles  = files { fileTree(dir: txtDir, includes: ['*.tex.txt']) }
	def ausgabe = new File(statsDir, 'tokens.xml')
	inputs.files inputFiles
	outputs.file ausgabe

	def delimiters = '\n\r\f \t!?#\$%^&*()[]=+<>/;:.,«»'
	// Dateien tokenisieren und Ergebnis in Map speichern.
	doLast {
		def liste = [:]
		inputFiles.each {
			def tokenizer = new StringTokenizer(it.text, delimiters, true)
			def lineNumber = 1
			try {
				// Process all tokens of one line.
				for (def token = tokenizer.nextToken(); token != null; token = tokenizer.nextToken()) {
					if (token == '\n') {
						lineNumber++
					}
					if (! delimiters.contains(token)) {
						if (token != '--') {
							if (! liste.get(token)) { liste[token] = [:] }
							if (! liste.get(token).get(it.name)) { liste[token][it.name] = [] }
							liste[token][it.name].add(lineNumber)
						}
					}
				}
			} catch (NoSuchElementException ex) { /* Done with the file. */ }
		}

		// Closure für Vorkommenzählung.
		def occurrenceCount = { occurrences ->
			def tokenCount = 0
			occurrences.each { k, v ->
				tokenCount += v.size()
			}
			tokenCount
		}
		
		// Sortieren nach Tokenname und Häufigkeit.
		liste = liste.sort { it.key}.sort { occurrenceCount(it.value) }
		
		// Map in XML-Datei umwandeln.
		def sw = new StringWriter()
		
		new groovy.xml.MarkupBuilder(sw).with {
			doubleQuotes = true
			def visitorLine = { 'line'('number': it) }
			def visitorToken = { k, v ->
				'occurrence' {
					'filename' { mkp.yield k }
					v.collect(visitorLine)
				}
			}
			def visitorTokens = { k, v ->
				'token' {
					'name' { mkp.yield k }
					'tokencount' { mkp.yield occurrenceCount(v) }
					'occurrences' {
						v.collect(visitorToken)
					}
				}
			}
			mkp.xmlDeclaration(version: '1.0')
			mkp.pi('xml-stylesheet': ['href': 'tokens.css', 'type': 'text/css'])
			'tokens' {
				'statistics' {
					'overalltokens' { mkp.yield liste.values().sum { occurrenceCount(it) } }
					'overalluniquetokens' { mkp.yield liste.size() }
					'tokenratio' { mkp.yield(liste.values().sum { occurrenceCount(it) } / liste.size()) }
				}
				liste.collect visitorTokens
			}
		}
		ausgabe.write sw.toString()
	}

}
